---
title: "3rd-Assignment"
author: "Andrea Češková, Tobias Grüner, Tuan Linh Tran"
format: html
editor: visual
---

```{r set-up, include=FALSE}
library(pacman)

pacman::p_load(
  httr,
 jsonlite,
 jose,
  ggplot2,
 keyring,
 ecmwfr,
  dplyr,
reticulate,
  geodata,
  sf,
 rvest,
  raster,
  rnaturalearth,
 rnaturalearthdata,
 grid,
 readr,
 ggspatial,
 gridExtra,
 kableExtra,
 ggrepel,
 tidygeocoder,
 osrm ,
  here,
  terra,
  tidyr,
  patchwork
)
here::i_am("R/3rd-Assignment.qmd")
```

# Introduction

We examine the correlation between population density and temperature across different land use types in the Netherlands. Our goal is to understand how land use mediates the relationship between temperature and population.

# Data

IMPORTANT: To download land use data you have to register here <https://land.copernicus.eu/en> for creating an API token. Then please save all the token information provided in a token.json!

```{r Check for token.json}

if (!file.exists(here("token.json"))) {
  warning("NO token.json created! Download of Land Cover data will fail.")
}
```

## Download and Pre-processing of Data

### Administrative boundaries

```{r Administrative boundaries}
# Administrive boundaries
nld_2 <- geodata::gadm(country = "NLD", level = 2, path=tempdir())
nld_2_sf <- st_as_sf(nld_2)
```

### Population Density

```{r}
# COMMENT TOBI: @Ling Where did you got the fine grained data from? I only found ~100m resolution for population density. However, the resolution of our temperature data set ist ~ 1km, so do we really need such fine grained data at this point? 

# pop <- raster(here("data","raw", "population_nld_2019-07-01_geotiff", "population_nld_2019-07-01.tif"))

# pop
# plot(pop)
if (!dir.exists(here("data/raw"))) {
  dir.create(here("data/raw"), recursive = TRUE)
}

url_pop <- "https://data.worldpop.org/GIS/Population/Global_2015_2030/R2024B/2019/NLD/v1/100m/constrained/nld_pop_2019_CN_100m_R2024B_v1.tif"

download.file(url_pop, destfile = here("data", "nld_population_2019.tif"), mode = "wb")
```

### Temperature

```{r CHELSA 2020}
# (latest) Annual Data of 2019, resolution ~1km

url <- "https://os.zhdk.cloud.switch.ch/chelsav2/EUR11/obs/annual/V2.1/bio01d/CHELSA_EUR11_obs_bio01d_2019_V.2.1.nc"

download.file(url, destfile = here("data", "raw", "CHELSA_EUR11_obs_bio01d_2019_V.2.1.nc"), mode = "wb")
temp <- rast(here("data", "raw", "CHELSA_EUR11_obs_bio01d_2019_V.2.1.nc")) 

temp_cropped <- crop(temp, nld_2)
temp_masked <- mask(temp_cropped, nld_2)

names(temp_masked)

writeRaster(temp_masked, here("data", "temp.nc"), overwrite=TRUE)

```

```{r EXPERIMENTAL: CHELSA 1981-2005}
# Annual Data of 1981-2005 (average),resolution ~1km

#url <- "https://os.zhdk.cloud.switch.ch/chelsav2/EUR11/obs/1981-2005/bio/CHELSA_ERA5_obs_bio01d_1981-2005_V.1.0.nc"

#download.file(url, destfile = here("data", "raw", "CHELSA_ERA5_obs_bio01d_1981-2005_V.1.0.nc"), mode = "wb")
#temp_series <- rast(here("data", "raw", "CHELSA_ERA5_obs_bio01d_1981-2005_V.1.0.nc")) 

#temp_series_cropped <- crop(temp_series, nld_2)
#temp_series_masked <- mask(temp_series_cropped, nld_2)

#plot(temp_series_masked)


# Plot for first impression
#temp_series_masked_df <- as.data.frame(temp_series_masked$tas, xy = TRUE, na.rm = TRUE)

#ggplot() +
#  geom_raster(data=temp_series_masked_df, aes(x=x, y=y, fill=tas)) +
#  scale_fill_viridis_c(option="viridis", name="Temperature") +
#  geom_sf(data=nld_2_sf, fill=NA, color="black", size=0.5)+
#  theme_minimal()

#plot(temp_series_masked)
```

### Land Cover

```{r Land Use vector API}
# I download the data as vector data as I would assume that it is easier for later calculation. But I haven't thought about it in detail.


#1st step search for UUID of DataSet
base_url <- "https://land.copernicus.eu/api/@search"

page_size <- 25
all_items <- list()
page <- 1

repeat {
  url <- paste0(base_url,
                "?portal_type=DataSet",
                "&batch_size=", page_size,
                "&b_start=", (page - 1) * page_size,
                "&metadata_fields=UID",
                "&metadata_fields=title",
                "&metadata_fields=dataset_download_information"
  )

  response <- GET(url, accept("application/json"))

  if (status_code(response) != 200) {
    stop("Request failed on page ", page, ": ", status_code(response))
  }

  content_json <- fromJSON(content(response, as = "text", encoding = "UTF-8"), flatten = TRUE)

  items <- content_json$items
  if (length(items) == 0) break

  all_items <- append(all_items, list(items))
  message("Page ", page, " loaded.")

  page <- page + 1
}

all_results <- bind_rows(all_items)

results <-subset(all_results, grepl("corine", title, ignore.case = TRUE))

uid <- "0407d497d3c44bcd93ce8fd5bf78596a"

subset <- results[results$UID == uid, ]
download_ids <- subset$dataset_download_information.items[[1]]
download_id <- download_ids[download_ids$full_format == "GDB", c("@id")]

# 2nd step: Decide in which format the items should be downloaded + spatial extent

# Get Bearer (private) key for API
service_key <- read_json(here("token.json"))

private_key <- service_key$private_key

claim <-jwt_claim(
  iss= service_key$client_id,
  sub= service_key$user_id,
  aud= service_key$token_uri,
  iat= as.integer(Sys.time()),
  exp= as.integer(Sys.time() + 60 * 60)
)

jwt <- jwt_encode_sig(claim, key = private_key)

base_url <- "https://land.copernicus.eu/@@oauth2-token"

Sys.sleep(10)
token_response <- POST(
  url = base_url,
  add_headers("Content-Type" = "application/x-www-form-urlencoded",
              Accept = "application/json"),
  body = list(
    grant_type = "urn:ietf:params:oauth:grant-type:jwt-bearer",
    assertion = jwt
  ),
  encode = "form"
)

if (status_code(token_response) != 200) {
    stop("Request for token failed, status: ", " ",status_code(token_response), "\nPlease check your token.json")
}

token_content <- fromJSON(content(token_response, as = "text", encoding = "UTF-8"), flatten = TRUE)
access_token <- token_content$access_token

# Projections that are available
proj_response <- GET(paste0("https://land.copernicus.eu/api/@projections?uid=", uid), accept("application/json"), add_headers(Authorization = paste("Bearer",access_token)))

if (status_code(proj_response) != 200) {
    stop("Request for projections failed", " ",status_code(proj_response), "\nMay access token is not correct. Did you run the code above successfully?")
  }

proj_content <- fromJSON(content(proj_response, as = "text", encoding = "UTF-8"), flatten = TRUE)

# Download actual data set with EPSG:4326
json_body <- list(
  Datasets = list(
    list(
      DatasetID = uid,
      DatasetDownloadInformationID = download_id,
      NUTS = "NL",
      OutputFormat = "GDB",
      OutputGCS = "EPSG:4326"
    )
  )
)

data_request_response <- POST(
  url = "https://land.copernicus.eu/api/@datarequest_post",
  add_headers("Content-Type" = "application/json",
              "Accept" = "application/json",
              "Authorization" = paste("Bearer", access_token)),
  body = toJSON(json_body, auto_unbox = TRUE),
  encode = "json"
)
if (status_code(data_request_response) == 429) {
    stop("Too many requests, please try last block again in ", headers(data_request_response)$"retry-after" ," seconds!")
}
if (status_code(data_request_response) != 201) {
    stop("Request for projections failed", " ",status_code(data_request_response), "\nMay access token is not correct. Did you run the code above successfully?")
}

data_request_response_json <- fromJSON(content(data_request_response, as = "text", encoding = "UTF-8"), flatten = TRUE)
tID <- data_request_response_json$TaskIds$TaskID

# Check if data is ready for download
repeat {
  status_request_response <- GET(
    url = paste0("https://land.copernicus.eu/api/@datarequest_status_get?TaskID=",tID),
    add_headers(
      "Accept" = "application/json",
      "Authorization" = paste("Bearer", access_token)
    )
  )
  if (status_code(status_request_response) == 429) {
      retry_after <- as.numeric(headers(status_request_response)[["retry-after"]])
      message("Too many requests (rate limiting), waiting... ", retry_after, " seconds...")
      Sys.sleep(retry_after)
      next
  }
  if (status_code(status_request_response) != 200) {
      stop("Request for projections failed (Status ", status_code(status_request_response), "). May wrong access token or task ID")
  }
  status_request_response_json <- fromJSON(content(status_request_response, as = "text", encoding = "UTF-8"), flatten = TRUE)
  current_status <- status_request_response_json$Status
  
  if (current_status == "Finished_ok") {
    download_url <- status_request_response_json$DownloadURL
    message("Request Finished!")
    break
  } else if (current_status %in% c("Failed", "Error", "Cancelled")) {
    stop("Request failed, status: ", current_status)
  }

  # Wait
  message("Request not yet completed. Retry in 60 seconds..")
  Sys.sleep(60)
}

```

```{r Corine Download and Pre-Processing}
# Download Land Use Data
download.file(download_url, destfile = here("data","raw", "CORINE_Land_Cover_2018.zip"), mode = "wb")
unzip(here("data", "raw", "CORINE_Land_Cover_2018.zip"), exdir = here("data/raw/Corine_Land_Cover_2018"))
file.remove(here("data","raw", "CORINE_Land_Cover_2018.zip"))

clc_nl <- st_read(here("data", "raw", "Corine_Land_Cover_2018", "Results", "U2018_CLC2018_V2020_20u1.gdb"))


# Way to add all 3 labels directly from the xls file
unzip(here("data","raw","Corine_Land_Cover_2018","Results","U2018_CLC2018_V2020_20u1_doc.zip"), exdir = here("data","raw","Corine_Land_Cover_2018"))

# Removing the old zip file
file.remove(here("data","raw","Corine_Land_Cover_2018","Results","U2018_CLC2018_V2020_20u1_doc.zip"))

# Reading the file
clc_labels <- read_excel(here("data","raw","Corine_Land_Cover_2018","Info","Legend","Vector","clc_legend.xls"))

# Saving separately each level
code_labels1 <- setNames(clc_labels$LABEL1, as.character(clc_labels$CLC_CODE))
code_labels2 <- setNames(clc_labels$LABEL2, as.character(clc_labels$CLC_CODE))
code_labels3 <- setNames(clc_labels$LABEL3, as.character(clc_labels$CLC_CODE))

# Applying all 3 to clc_nl
clc_nl$Label1 <- code_labels1[as.character(clc_nl$Code_18)]
clc_nl$Label2 <- code_labels2[as.character(clc_nl$Code_18)]
clc_nl$Label3 <- code_labels3[as.character(clc_nl$Code_18)]

# Writing the labeled spatial data with all labels
st_write(clc_nl, here("data", "clc_nl.gpkg"), delete_layer = TRUE)
```

### Overview over data sets

+------------------------------------+----------------------+----------------------------+--------------------------------------------+------------+
| DataSet                            | Automatic extraction | Format                     | Resolution                                 | Projection |
+====================================+======================+============================+============================================+============+
| GADMN (admin. boundaries), Level 2 | Yes                  | Vector                     | \-                                         | WGS 84     |
|                                    |                      |                            |                                            |            |
|                                    |                      | nld_2: SpatVector (terra)  |                                            |            |
|                                    |                      |                            |                                            |            |
|                                    |                      | nld_2_sf: sf-Object        |                                            |            |
+------------------------------------+----------------------+----------------------------+--------------------------------------------+------------+
| CHELSA (temperature data)          | Yes                  | temp: SpatRaster (terra)   | Raster 0.008333333                         | WGS 84     |
|                                    |                      |                            |                                            |            |
| --\> Average temperature in 2019   |                      | temp_df: DataFrame         | \~ 930 m (North-South) x 570 m (East-West) |            |
+------------------------------------+----------------------+----------------------------+--------------------------------------------+------------+
| HDX (population density)           | Yes                  | Raster                     | 0.008333333                                | WGS 84     |
|                                    |                      |                            |                                            |            |
| 2019                               |                      | pop2: SpatRaster (terra)   | \~ 930 m (North-South) x 570 m (East-West) |            |
+------------------------------------+----------------------+----------------------------+--------------------------------------------+------------+
| Corine (Land Use)                  | Yes                  | Vector\                    | 0.008333333                                | WGS 84     |
|                                    |                      | clc_nl: SpatVector (terra) |                                            |            |
|                                    |                      |                            | \~ 930 m (North-South) x 570 m (East-West) |            |
|                                    |                      | clc_nl_sf: sf-object       |                                            |            |
+------------------------------------+----------------------+----------------------------+--------------------------------------------+------------+

## Load downloaded data in memory

```{r load data sets}
# Population density
pop2 <- rast(here("data", "nld_population_2019.tif"))

# Administrive boundaries
nld_2 <- geodata::gadm(country = "NLD", level = 2, path=tempdir())
nld_2_sf <- st_as_sf(nld_2)

# Temperature
temp <- rast(here("data", "temp.nc"))
temp_df <- as.data.frame(temp, xy = TRUE, na.rm = TRUE)

# Land Use
clc_nl <- vect(here("data", "clc_nl.gpkg"))
clc_nl_sf <- st_as_sf(clc_nl)
# Plotting for understanding data
plot(pop2)
ggplot() +
  geom_raster(data=temp_df, aes(x=x, y=y, fill=Band1)) +
  scale_fill_viridis_c(option="viridis", name="Temperature (2019)") +
  geom_sf(data=nld_2_sf, fill=NA, color="black", size=0.5)+
  theme_minimal()

# Plot clc
top_labels <- names(sort(tapply(clc_nl_sf$Area_Ha, clc_nl_sf$Label1, sum), decreasing = TRUE))[1:7]
clc_nl_sf$filtered_label <- ifelse(clc_nl_sf$Label1 %in% top_labels, clc_nl_sf$Label1, "Others")

palette_clc <- hsv(h = seq(0, 1-1/length(unique(clc_nl_sf$filtered_label)), length.out = length(unique(clc_nl_sf$filtered_label))),
                   s = 0.6, v = 0.9)

names(palette_clc) <- unique(clc_nl_sf$filtered_label)
ggplot(clc_nl_sf) +
  geom_sf(aes(fill = filtered_label), color = NA) +
  scale_fill_manual(values = c(palette_clc[top_labels], "Others" = "gray80")) +
  theme_minimal()

```
